Train:
  batch_size: 128
  learning_rate: 0.05
  reg: 0.00005
  epochs: 15
  steps: [6, 8]
  warmup: 0
  momentum: 0.9
  embed_dim: 1024
  num_classes: 1048

network:
  model: im2recipe

data:
  data_path: '../../../../../../../Desktop/DL/'
  maxlen: 20
  vocab: 'vocab.txt'
  save_best: False

ingredient_lstm:
  ingredient_lstm_dim: 300
  ingredient_embedding_dim: 300 # vocab size 30167 x 300 embedded
  ingredient_w2v_path: '../../../../../../../Desktop/DL/unpacked/vocab.bin'

recipe_lstm:
  recipe_lstm_dim: 1024
  recipe_embedding_dim: 1024
