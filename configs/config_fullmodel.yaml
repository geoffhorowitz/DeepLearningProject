Train:
  batch_size: 4
  learning_rate: 0.005
  epochs: 5
  embed_dim: 1024
  num_classes: 1048
  train_percent: 0.1
  val_percent: 0.05
  semantic_reg: False
  cos_weight: 0.8
  image_weight: 0.1
  recipe_weight: 0.1
  workers: 4
  mismatch: 0.5

network:
  model: im2recipe
  recipe_model: 'transformer' # lstm or transformer

data:
  #data_path: '../../../../../../../Desktop/DL/'
  #image_path: '../../../../../../../Desktop/DL/test'
  data_path: '../../../../../../../Desktop/DL/data'
  image_path: '../../../../../../../Desktop/DL/data/images'
  generate_metrics: False
  metric_type: 'accuracy' # rank or accuracy
  save_best: False

image_model:
  freeze_image: True

ingredient_lstm:
  ingredient_lstm_dim: 300
  ingredient_embedding_dim: 300 # vocab size 30167 x 300 embedded
  ingredient_w2v_path: '../../../../../../../Desktop/DL/data/vocab.bin'
  ingred_model_variant: 'custom_fusion' # basic, custom_fusion, paper

recipe_lstm:
  recipe_lstm_dim: 1024
  recipe_embedding_dim: 1024
  recipe_model_variant: 'custom_fusion' # basic, custom_basic, custom_fusion, paper

transformer:
    hidden_dim: 256
    num_heads: 4 # 2 original
    dim_feedforward: 256 # 2048 original
